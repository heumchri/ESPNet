{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/heumchri/ESPNet/blob/master/binaryESPNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WPmTvrCSU42W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# general"
      ]
    },
    {
      "metadata": {
        "id": "shHCBH0iJewE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9uo8rt862To",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls /content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ENklW_Q4g207",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## utilization monitoring"
      ]
    },
    {
      "metadata": {
        "id": "LFOeJjrChDec",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#requirements for gpu and ram usage\n",
        "\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9ClMeG-VIfn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#gpu and ram usage\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsibX7-1hDeg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#running processes\n",
        "\n",
        "#!ps -aux\n",
        "!ps -aux | grep python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVThw0JoIjDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#storage usage\n",
        "\n",
        "!df -h "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ugsppsq0fKlS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## increase shm for multithreading to work"
      ]
    },
    {
      "metadata": {
        "id": "L7cut4qWKEgL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /etc/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EMrBeJdNV0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%writefile fstab\n",
        "tmpfs /dev/shm tmpfs defaults,size=2G 0 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uEhKvrc4NikO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mount -o remount /dev/shm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNMu-qwjkqLk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#storage usage\n",
        "\n",
        "!df -h "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DZ9YgkO1HIQS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# mount google drive"
      ]
    },
    {
      "metadata": {
        "id": "zOc4Mdw7HJ6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "#!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "#!apt-get update -qq 2>&1 > /dev/null\n",
        "#!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!wget https://launchpad.net/~alessandro-strada/+archive/ubuntu/google-drive-ocamlfuse-beta/+build/15331130/+files/google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!dpkg -i google-drive-ocamlfuse_0.7.0-0ubuntu1_amd64.deb\n",
        "!apt-get install -f\n",
        "!apt-get -y install -qq fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vdkxblGwHR3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8grQFFcYICZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dwlWt0DiIEQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9f4Gdj-TU-A-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install ESPNet"
      ]
    },
    {
      "metadata": {
        "id": "UrlaSAp1Gt6o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ktKvHeTzDpxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEaxMybUPsHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T3KONFD0Dw1T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/heumchri/ESPNet.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FBre1MUdZg3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GMulAjkTZTAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "--Mhfpls9Ejg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test forward time\n",
        "20 classes:\n",
        "\n",
        "decoder batch 1: 0.045\n",
        "\n",
        "decoder batch 16: 0.027\n",
        "\n",
        "encoder batch 1: 0.034\n",
        "\n",
        "encoder batch 16: 0.020\n",
        "\n",
        "binary: \n",
        "\n",
        "decoder batch 1: 0.038\n",
        "\n",
        "decoder batch 16: 0.022\n",
        "\n",
        "encoder batch 1: 0.034\n",
        "\n",
        "encoder batch 16: 0.020"
      ]
    },
    {
      "metadata": {
        "id": "_5R-Nfen9G84",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulg5orvs9LuC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 eval_forwardTime_pretrained.py --batch-size 1 --modelType 1 --classes 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UMQjYHBmRNnf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 eval_forwardTime.py --batch-size 1 --modelType 1 --classes 2 --weightsDir /content/drive/espnet_checkpoints/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oprehLyzx2mv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (all classes, val dataset) 0.952"
      ]
    },
    {
      "metadata": {
        "id": "NvTRp4dyx2mw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GQjU0iakx2my",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/frankfurt/\n",
        "!python3 VisualizeResults.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/lindau/\n",
        "!python3 VisualizeResults.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/munster/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "raHTu9Tnx2m0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "Rndn0tDnx2m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CHDN6s2Kx2m1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "#Image('/content/datasets/cityscapes/leftImg8bit/val/munster/munster_000000_000019_leftImg8bit.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mT--Kmmx2m6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('/content/datasets/cityscapes/gtFine/val/munster/munster_000000_000019_gtFine_color.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UY9672wlx2m4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/c_munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fuIFkgfPWDqp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_munster_000000_000019_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4nkNLBEyx2m5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3tuWRhZax2m-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "WbdCBrZqx2m_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/ESPNet/test/results/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MGMCSnIcx2nA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G0kAMrYmx2nB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9MPJCmJxzZI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (binary, val dataset) 0.952"
      ]
    },
    {
      "metadata": {
        "id": "OaC-mLvXxzZE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OG3IsCTbxzZA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults_pretrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/frankfurt/\n",
        "!python3 VisualizeResults_pretrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/lindau/\n",
        "!python3 VisualizeResults_pretrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/munster/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vob6V8gSWusA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "aIWwCOYNWusC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eXbl_YAmWusC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "#Image('/content/datasets/cityscapes/leftImg8bit/val/munster/munster_000000_000019_leftImg8bit.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WFUE-999WusD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('/content/datasets/cityscapes/gtFine/val/munster/munster_000000_000019_gtFine_color.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AkliEFHQWusE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/c_munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aTblAR7IWusF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_munster_000000_000019_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rXv73ZxXWusG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dnZqczlPxzYx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "CFBj7Fs1xzYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/ESPNet/test/results/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vIKjagozxzYs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mRyKfcrHxzYp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDk_LDoRCfXv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test pretrained model (all classes, val dataset, only encoder) 0.926"
      ]
    },
    {
      "metadata": {
        "id": "_gMh4rhMCfXv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSVI5VqVCfXx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/frankfurt/\n",
        "!python3 VisualizeResults.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/lindau/\n",
        "!python3 VisualizeResults.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/munster/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "exaHlpy3ZqQy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "FrPPy3S6ZqQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLlnDzGbZqQz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "#Image('/content/datasets/cityscapes/leftImg8bit/val/munster/munster_000000_000019_leftImg8bit.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SKF0b_U3ZqQ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('/content/datasets/cityscapes/gtFine/val/munster/munster_000000_000019_gtFine_color.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Q8swyQcZqQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/c_munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EcuLA9TpZqQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_munster_000000_000019_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x6zloLfBZqQ3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5NXylSyXCfX6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "a_yVL4_LCfX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/ESPNet/test/results/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_rlbvVk1CfX7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ixhj3qHXCfX9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KCDlc9qRlkZ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained model (binary, val dataset, only encoder) 0.950\n",
        "**epoch 16 (= model_17.pth, best val loss) : 0.944**\n",
        "\n",
        "**epoch 6 (best road val Acc) : 0.934**\n",
        "\n",
        "**epoch 9 (best val mAcc) : 0.938 **\n",
        "\n",
        "**epoch 112 : 0.947**\n",
        "\n",
        "**epoch 220 (best road val IoU, best val mIoU) : 0.950**"
      ]
    },
    {
      "metadata": {
        "id": "jOgiiuaBlkZ9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IToHOKElkZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults_retrained_binary.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/frankfurt/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/lindau/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 2 --data_dir /content/datasets/cityscapes/leftImg8bit/val/munster/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A1-CSj7VZtMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "df4DlzYHZtMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MRX9qkvTZtMD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "#Image('/content/datasets/cityscapes/leftImg8bit/val/munster/munster_000000_000019_leftImg8bit.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PT7g5DlyZtME",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('/content/datasets/cityscapes/gtFine/val/munster/munster_000000_000019_gtFine_color.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LP-YF8UiZtMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/c_munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VJWJTHyDZtMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_munster_000000_000019_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_gxilqvwZtMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TaaxeBZOlkaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "1-egZSJ1lkaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/ESPNet/test/results/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UO0I2zx6lkaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lk-GYaeolkaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyVOXJWOr1sR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# test retrained model (binary, val dataset) 0.958\n",
        "**epoch 156: 0.952**\n",
        "\n",
        "**epoch 227: 0.958**"
      ]
    },
    {
      "metadata": {
        "id": "xWj1wR_8r1sV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0J5hoR1Pr1se",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/frankfurt/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/lindau/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/val/munster/ --classes 2 --weightsDir /content/drive/espnet_checkpoints/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AQ_PGISEZxt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## visualize results"
      ]
    },
    {
      "metadata": {
        "id": "pln7E5N4Zxt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bp1WNfUXZxt8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "#Image('/content/datasets/cityscapes/leftImg8bit/val/munster/munster_000000_000019_leftImg8bit.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZLc2LKmVZxt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('/content/datasets/cityscapes/gtFine/val/munster/munster_000000_000019_gtFine_color.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PCafa9AyZxt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/c_munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBraOBwUZxt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_munster_000000_000019_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7MJSIZtlZxuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Image('results/munster_000000_000019_leftImg8bit.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q5NhR8N0r1tH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## evaluate results"
      ]
    },
    {
      "metadata": {
        "id": "jwdPBy26r1tI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CITYSCAPES_RESULTS'] = '/content/ESPNet/test/results/'\n",
        "os.environ['CITYSCAPES_DATASET'] = '/content/datasets/cityscapes/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NHYlY84Sr1tL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/cityscapesScripts/cityscapesscripts/evaluation/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EalqCkuyr1tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python2 evalPixelLevelSemanticLabeling.py "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XitPIDtcLSb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# qualitative test retrained model (binary)"
      ]
    },
    {
      "metadata": {
        "id": "I26JEBBUs5PL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##cityscapes video"
      ]
    },
    {
      "metadata": {
        "id": "4Rv6vDOTcqmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/cityscapes/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJiq_qHoZF9D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --keep-session-cookies --save-cookies=cookies.txt --post-data 'username=heumann.christopher&password=xxx&submit=Login' https://www.cityscapes-dataset.com/login/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aAMF4M0WZU2Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHEN1yYqquMm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip leftImg8bit_demoVideo.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIAksj26d_wj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm cookies.txt index.html README leftImg8bit_demoVideo.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aSwrKz7NcLSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55-X57AwcLSd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/demoVideo/stuttgart_00/ --classes 2 --weightsDir /content/ESPNet/retrained_binary/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/demoVideo/stuttgart_01/ --classes 2 --weightsDir /content/ESPNet/retrained_binary/\n",
        "!python3 VisualizeResults_retrained_binary.py --modelType 1 --data_dir /content/datasets/cityscapes/leftImg8bit/demoVideo/stuttgart_02/ --classes 2 --weightsDir /content/ESPNet/retrained_binary/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zG2hnKL0cLSe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### visualize results"
      ]
    },
    {
      "metadata": {
        "id": "N96IiRcwcLSe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls results/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wVudpiVEcLSf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KmPp8nwhcLSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Image('results/over_stuttgart_00_000000_000001_leftImg8bit.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pk0F2AQkkXNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_sZAUN0k-Bt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 24 -pattern_type glob -i 'results/over_stuttgart_00*.jpg' -c:v libx264 -pix_fmt yuv420p over_stuttgart_00.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "InVy8zpdthbw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 24 -pattern_type glob -i 'results/over_stuttgart_01*.jpg' -c:v libx264 -pix_fmt yuv420p over_stuttgart_01.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JPxs_bBgtj5Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 24 -pattern_type glob -i 'results/over_stuttgart_02*.jpg' -c:v libx264 -pix_fmt yuv420p over_stuttgart_02.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7xp2KzsinSpN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('over_stuttgart_00.mp4')\n",
        "files.download('over_stuttgart_01.mp4')\n",
        "files.download('over_stuttgart_02.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y4v9oxWDs9mb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##apex video"
      ]
    },
    {
      "metadata": {
        "id": "ngmC9Wvfy2ZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/datasets/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHKyntmJs9mi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/drive/apex/images/1.zip -d /content/datasets/apex/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JlwHSd5DxP3b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/apex/1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7l5Zn5C-0ANG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rename 's/\\d+/sprintf(\"%05d\",$&)/e' frame*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W4N7y-Hps9ml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/test/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uu5Dk9iMaUqX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### input bilinear to 1024x512, output bilinear to 1368x1096"
      ]
    },
    {
      "metadata": {
        "id": "-py_P36HicqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args_model=\"ESPNet\"#, help='Model name')\n",
        "args_data_dir=\"/content/datasets/apex/1/\"#, help='Data directory')\n",
        "args_img_extn=\"jpg\"#, help='RGB Image format')\n",
        "args_inWidth=1024#, help='Width of RGB image')\n",
        "args_inHeight=512#, help='Height of RGB image')\n",
        "args_scaleIn=1#, help='For ESPNet-C, scaleIn=8. For ESPNet, scaleIn=1')\n",
        "args_modelType=1#, help='1=ESPNet, 2=ESPNet-C')\n",
        "args_savedir='./results1'#, help='directory to save the results')\n",
        "args_gpu=True#, help='Run on CPU or GPU. If TRUE, then GPU.')\n",
        "args_decoder=True#,help='True if ESPNet. False for ESPNet-C')  # False for encoder\n",
        "args_weightsDir='/content/ESPNet/retrained_binary/'#, help='Pretrained weights directory.')\n",
        "args_p=2#, help='depth multiplier. Supported only 2')\n",
        "args_q=8#, help='depth multiplier. Supported only 3, 5, 8')\n",
        "args_cityFormat=True#, help='If you want to convert to cityscape '\n",
        "                                                                       #'original label ids')\n",
        "args_colored=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks in color')\n",
        "args_overlay=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks overlayed on top of RGB image')\n",
        "args_classes=2#, type=int, help='Number of classes in the dataset. 20 for Cityscapes')\n",
        "\n",
        "assert args_modelType == 1 and args_decoder#, 'Model type should be 2 for ESPNet-C and 1 for ESPNet'\n",
        "if args_overlay:\n",
        "    args_colored = True # This has to be true if you want to overlay\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image as PILImage\n",
        "import Model as Net\n",
        "import os\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "pallete = [[0, 255, 0],\n",
        "           [0, 0, 0]]\n",
        "\n",
        "\n",
        "def relabel(img):\n",
        "    '''\n",
        "    This function relabels the predicted labels so that cityscape dataset can process\n",
        "    :param img:\n",
        "    :return:\n",
        "    '''\n",
        "    img[img == 0] = 7\n",
        "    img[img == 1] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "def evaluateModel_resizeInput_resizeOutput(model, up, image_list):\n",
        "    # gloabl mean and std values\n",
        "    mean = [72.3923111, 82.90893555, 73.15840149]\n",
        "    std = [45.3192215, 46.15289307, 44.91483307]\n",
        "\n",
        "    for i, imgName in enumerate(image_list):\n",
        "        img = cv2.imread(imgName)\n",
        "        if args_overlay:\n",
        "            img_orig = np.copy(img)\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "        for j in range(3):\n",
        "            img[:, :, j] -= mean[j]\n",
        "        for j in range(3):\n",
        "            img[:, :, j] /= std[j]\n",
        "\n",
        "        # resize the image to 1024x512x3\n",
        "        img = cv2.resize(img, (1024, 512))\n",
        "\n",
        "        img /= 255\n",
        "        img = img.transpose((2, 0, 1))\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = torch.unsqueeze(img_tensor, 0)  # add a batch dimension\n",
        "        img_variable = Variable(img_tensor, volatile=True)\n",
        "        if args_gpu:\n",
        "            img_variable = img_variable.cuda()\n",
        "        img_out = model(img_variable)\n",
        "\n",
        "        img_out = up(img_out)\n",
        "\n",
        "        classMap_numpy = img_out[0].max(0)[1].byte().cpu().data.numpy()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "\n",
        "        name = imgName.split('/')[-1]\n",
        "\n",
        "        if args_colored:\n",
        "            classMap_numpy_color = np.zeros((img_orig.shape[0], img_orig.shape[1], img_orig.shape[2]), dtype=np.uint8)\n",
        "            for idx in range(len(pallete)):\n",
        "                [r, g, b] = pallete[idx]\n",
        "                classMap_numpy_color[classMap_numpy == idx] = [b, g, r]\n",
        "            cv2.imwrite(args_savedir + os.sep + 'c_' + name.replace(args_img_extn, 'png'), classMap_numpy_color)\n",
        "            if args_overlay:\n",
        "                output_grey = cv2.cvtColor(classMap_numpy_color,cv2.COLOR_BGR2GRAY)\n",
        "                ret, mask = cv2.threshold(output_grey, 0, 255, cv2.THRESH_BINARY_INV)\n",
        "                orig_masked = cv2.bitwise_or(img_orig, img_orig, mask=mask)\n",
        "                orig_colored = dst = cv2.add(classMap_numpy_color,orig_masked)\n",
        "                overlayed = cv2.addWeighted(orig_colored, 0.5, img_orig, 0.5, 0)\n",
        "                cv2.imwrite(args_savedir + os.sep + 'over_' + name.replace(args_img_extn, 'jpg'), overlayed)\n",
        "\n",
        "        if args_cityFormat:\n",
        "            classMap_numpy = relabel(classMap_numpy.astype(np.uint8))\n",
        "\n",
        "        cv2.imwrite(args_savedir + os.sep + name.replace(args_img_extn, 'png'), classMap_numpy)\n",
        "\n",
        "\n",
        "def main_resizeInput_resizeOutput():\n",
        "    # read all the images in the folder\n",
        "    image_list = glob.glob(args_data_dir + os.sep + '*.' + args_img_extn)\n",
        "\n",
        "    up = None\n",
        "    if args_modelType == 2:\n",
        "        up = torch.nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "    else:\n",
        "        up = torch.nn.Upsample(size=(1096,1368), mode='bilinear')\n",
        "    if args_gpu:\n",
        "        up = up.cuda()\n",
        "\n",
        "    p = args_p\n",
        "    q = args_q\n",
        "    classes = args_classes\n",
        "    if args_modelType == 2:\n",
        "        modelA = Net.ESPNet_Encoder(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'encoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(\n",
        "            q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/encoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    elif args_modelType == 1:\n",
        "        modelA = Net.ESPNet(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'decoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/decoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    else:\n",
        "        print('Model not supported')\n",
        "    # modelA = torch.nn.DataParallel(modelA)\n",
        "    if args_gpu:\n",
        "        modelA = modelA.cuda()\n",
        "\n",
        "    # set to evaluation mode\n",
        "    modelA.eval()\n",
        "\n",
        "    if not os.path.isdir(args_savedir):\n",
        "        os.mkdir(args_savedir)\n",
        "\n",
        "    evaluateModel_resizeInput_resizeOutput(modelA, up, image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "72JzxTWpm33M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_resizeInput_resizeOutput()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8lxDzMacayxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### input unchanged, output unchanged"
      ]
    },
    {
      "metadata": {
        "id": "dBOaCfcJayxx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args_model=\"ESPNet\"#, help='Model name')\n",
        "args_data_dir=\"/content/datasets/apex/1/\"#, help='Data directory')\n",
        "args_img_extn=\"jpg\"#, help='RGB Image format')\n",
        "args_inWidth=1024#, help='Width of RGB image')\n",
        "args_inHeight=512#, help='Height of RGB image')\n",
        "args_scaleIn=1#, help='For ESPNet-C, scaleIn=8. For ESPNet, scaleIn=1')\n",
        "args_modelType=1#, help='1=ESPNet, 2=ESPNet-C')\n",
        "args_savedir='./results1'#, help='directory to save the results')\n",
        "args_gpu=True#, help='Run on CPU or GPU. If TRUE, then GPU.')\n",
        "args_decoder=True#,help='True if ESPNet. False for ESPNet-C')  # False for encoder\n",
        "args_weightsDir='/content/ESPNet/retrained_binary/'#, help='Pretrained weights directory.')\n",
        "args_p=2#, help='depth multiplier. Supported only 2')\n",
        "args_q=8#, help='depth multiplier. Supported only 3, 5, 8')\n",
        "args_cityFormat=True#, help='If you want to convert to cityscape '\n",
        "                                                                       #'original label ids')\n",
        "args_colored=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks in color')\n",
        "args_overlay=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks overlayed on top of RGB image')\n",
        "args_classes=2#, type=int, help='Number of classes in the dataset. 20 for Cityscapes')\n",
        "\n",
        "assert args_modelType == 1 and args_decoder#, 'Model type should be 2 for ESPNet-C and 1 for ESPNet'\n",
        "if args_overlay:\n",
        "    args_colored = True # This has to be true if you want to overlay\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image as PILImage\n",
        "import Model as Net\n",
        "import os\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "pallete = [[0, 255, 0],\n",
        "           [0, 0, 0]]\n",
        "\n",
        "\n",
        "def relabel(img):\n",
        "    '''\n",
        "    This function relabels the predicted labels so that cityscape dataset can process\n",
        "    :param img:\n",
        "    :return:\n",
        "    '''\n",
        "    img[img == 0] = 7\n",
        "    img[img == 1] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "def evaluateModel(model, up, image_list):\n",
        "    # gloabl mean and std values\n",
        "    mean = [72.3923111, 82.90893555, 73.15840149]\n",
        "    std = [45.3192215, 46.15289307, 44.91483307]\n",
        "\n",
        "    for i, imgName in enumerate(image_list):\n",
        "        img = cv2.imread(imgName)\n",
        "        if args_overlay:\n",
        "            img_orig = np.copy(img)\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "        for j in range(3):\n",
        "            img[:, :, j] -= mean[j]\n",
        "        for j in range(3):\n",
        "            img[:, :, j] /= std[j]\n",
        "\n",
        "        # resize the image to 1024x512x3\n",
        "        #img = cv2.resize(img, (1024, 512))\n",
        "\n",
        "        img /= 255\n",
        "        img = img.transpose((2, 0, 1))\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = torch.unsqueeze(img_tensor, 0)  # add a batch dimension\n",
        "        img_variable = Variable(img_tensor, volatile=True)\n",
        "        if args_gpu:\n",
        "            img_variable = img_variable.cuda()\n",
        "        img_out = model(img_variable)\n",
        "\n",
        "        #img_out = up(img_out)\n",
        "\n",
        "        classMap_numpy = img_out[0].max(0)[1].byte().cpu().data.numpy()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "\n",
        "        name = imgName.split('/')[-1]\n",
        "\n",
        "        if args_colored:\n",
        "            classMap_numpy_color = np.zeros((img_orig.shape[0], img_orig.shape[1], img_orig.shape[2]), dtype=np.uint8)\n",
        "            for idx in range(len(pallete)):\n",
        "                [r, g, b] = pallete[idx]\n",
        "                classMap_numpy_color[classMap_numpy == idx] = [b, g, r]\n",
        "            cv2.imwrite(args_savedir + os.sep + 'c_' + name.replace(args_img_extn, 'png'), classMap_numpy_color)\n",
        "            if args_overlay:\n",
        "                output_grey = cv2.cvtColor(classMap_numpy_color,cv2.COLOR_BGR2GRAY)\n",
        "                ret, mask = cv2.threshold(output_grey, 0, 255, cv2.THRESH_BINARY_INV)\n",
        "                orig_masked = cv2.bitwise_or(img_orig, img_orig, mask=mask)\n",
        "                orig_colored = dst = cv2.add(classMap_numpy_color,orig_masked)\n",
        "                overlayed = cv2.addWeighted(orig_colored, 0.5, img_orig, 0.5, 0)\n",
        "                cv2.imwrite(args_savedir + os.sep + 'over_' + name.replace(args_img_extn, 'jpg'), overlayed)\n",
        "\n",
        "        if args_cityFormat:\n",
        "            classMap_numpy = relabel(classMap_numpy.astype(np.uint8))\n",
        "\n",
        "        cv2.imwrite(args_savedir + os.sep + name.replace(args_img_extn, 'png'), classMap_numpy)\n",
        "\n",
        "\n",
        "def main():\n",
        "    # read all the images in the folder\n",
        "    image_list = glob.glob(args_data_dir + os.sep + '*.' + args_img_extn)\n",
        "\n",
        "    up = None\n",
        "    if args_modelType == 2:\n",
        "        up = torch.nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "    else:\n",
        "        up = torch.nn.Upsample(size=(1096,1368), mode='bilinear')\n",
        "    if args_gpu:\n",
        "        up = up.cuda()\n",
        "\n",
        "    p = args_p\n",
        "    q = args_q\n",
        "    classes = args_classes\n",
        "    if args_modelType == 2:\n",
        "        modelA = Net.ESPNet_Encoder(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'encoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(\n",
        "            q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/encoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    elif args_modelType == 1:\n",
        "        modelA = Net.ESPNet(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'decoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/decoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    else:\n",
        "        print('Model not supported')\n",
        "    # modelA = torch.nn.DataParallel(modelA)\n",
        "    if args_gpu:\n",
        "        modelA = modelA.cuda()\n",
        "\n",
        "    # set to evaluation mode\n",
        "    modelA.eval()\n",
        "\n",
        "    if not os.path.isdir(args_savedir):\n",
        "        os.mkdir(args_savedir)\n",
        "\n",
        "    evaluateModel(modelA, up, image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBUwclevayxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNvRk091c6ko",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### input bilinear to 1024x512, output unchanged"
      ]
    },
    {
      "metadata": {
        "id": "i5ifAPEnc6kp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "args_model=\"ESPNet\"#, help='Model name')\n",
        "args_data_dir=\"/content/datasets/apex/1/\"#, help='Data directory')\n",
        "args_img_extn=\"jpg\"#, help='RGB Image format')\n",
        "args_inWidth=1024#, help='Width of RGB image')\n",
        "args_inHeight=512#, help='Height of RGB image')\n",
        "args_scaleIn=1#, help='For ESPNet-C, scaleIn=8. For ESPNet, scaleIn=1')\n",
        "args_modelType=1#, help='1=ESPNet, 2=ESPNet-C')\n",
        "args_savedir='./results1'#, help='directory to save the results')\n",
        "args_gpu=True#, help='Run on CPU or GPU. If TRUE, then GPU.')\n",
        "args_decoder=True#,help='True if ESPNet. False for ESPNet-C')  # False for encoder\n",
        "args_weightsDir='/content/ESPNet/retrained_binary/'#, help='Pretrained weights directory.')\n",
        "args_p=2#, help='depth multiplier. Supported only 2')\n",
        "args_q=8#, help='depth multiplier. Supported only 3, 5, 8')\n",
        "args_cityFormat=True#, help='If you want to convert to cityscape '\n",
        "                                                                       #'original label ids')\n",
        "args_colored=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks in color')\n",
        "args_overlay=True#, type=bool, help='If you want to visualize the '\n",
        "                                                                   #'segmentation masks overlayed on top of RGB image')\n",
        "args_classes=2#, type=int, help='Number of classes in the dataset. 20 for Cityscapes')\n",
        "\n",
        "assert args_modelType == 1 and args_decoder#, 'Model type should be 2 for ESPNet-C and 1 for ESPNet'\n",
        "if args_overlay:\n",
        "    args_colored = True # This has to be true if you want to overlay\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import glob\n",
        "import cv2\n",
        "from PIL import Image as PILImage\n",
        "import Model as Net\n",
        "import os\n",
        "import time\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "pallete = [[0, 255, 0],\n",
        "           [0, 0, 0]]\n",
        "\n",
        "\n",
        "def relabel(img):\n",
        "    '''\n",
        "    This function relabels the predicted labels so that cityscape dataset can process\n",
        "    :param img:\n",
        "    :return:\n",
        "    '''\n",
        "    img[img == 0] = 7\n",
        "    img[img == 1] = 0\n",
        "    return img\n",
        "\n",
        "\n",
        "def evaluateModel_resizeInput(model, up, image_list):\n",
        "    # gloabl mean and std values\n",
        "    mean = [72.3923111, 82.90893555, 73.15840149]\n",
        "    std = [45.3192215, 46.15289307, 44.91483307]\n",
        "\n",
        "    for i, imgName in enumerate(image_list):\n",
        "        img = cv2.imread(imgName)\n",
        "        if args_overlay:\n",
        "            img_orig = np.copy(img)\n",
        "            img_orig = cv2.resize(img, (1024, 512))\n",
        "\n",
        "        img = img.astype(np.float32)\n",
        "        for j in range(3):\n",
        "            img[:, :, j] -= mean[j]\n",
        "        for j in range(3):\n",
        "            img[:, :, j] /= std[j]\n",
        "\n",
        "        # resize the image to 1024x512x3\n",
        "        img = cv2.resize(img, (1024, 512))\n",
        "\n",
        "        img /= 255\n",
        "        img = img.transpose((2, 0, 1))\n",
        "        img_tensor = torch.from_numpy(img)\n",
        "        img_tensor = torch.unsqueeze(img_tensor, 0)  # add a batch dimension\n",
        "        img_variable = Variable(img_tensor, volatile=True)\n",
        "        if args_gpu:\n",
        "            img_variable = img_variable.cuda()\n",
        "        img_out = model(img_variable)\n",
        "\n",
        "        classMap_numpy = img_out[0].max(0)[1].byte().cpu().data.numpy()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(i)\n",
        "\n",
        "        name = imgName.split('/')[-1]\n",
        "\n",
        "        if args_colored:\n",
        "            classMap_numpy_color = np.zeros((img_orig.shape[0], img_orig.shape[1], img_orig.shape[2]), dtype=np.uint8)\n",
        "            for idx in range(len(pallete)):\n",
        "                [r, g, b] = pallete[idx]\n",
        "                classMap_numpy_color[classMap_numpy == idx] = [b, g, r]\n",
        "            cv2.imwrite(args_savedir + os.sep + 'c_' + name.replace(args_img_extn, 'png'), classMap_numpy_color)\n",
        "            if args_overlay:\n",
        "                output_grey = cv2.cvtColor(classMap_numpy_color,cv2.COLOR_BGR2GRAY)\n",
        "                ret, mask = cv2.threshold(output_grey, 0, 255, cv2.THRESH_BINARY_INV)\n",
        "                orig_masked = cv2.bitwise_or(img_orig, img_orig, mask=mask)\n",
        "                orig_colored = dst = cv2.add(classMap_numpy_color,orig_masked)\n",
        "                overlayed = cv2.addWeighted(orig_colored, 0.5, img_orig, 0.5, 0)\n",
        "                cv2.imwrite(args_savedir + os.sep + 'over_' + name.replace(args_img_extn, 'jpg'), overlayed)\n",
        "\n",
        "        if args_cityFormat:\n",
        "            classMap_numpy = relabel(classMap_numpy.astype(np.uint8))\n",
        "\n",
        "        cv2.imwrite(args_savedir + os.sep + name.replace(args_img_extn, 'png'), classMap_numpy)\n",
        "\n",
        "\n",
        "def main_resizeInput():\n",
        "    # read all the images in the folder\n",
        "    image_list = glob.glob(args_data_dir + os.sep + '*.' + args_img_extn)\n",
        "\n",
        "    up = None\n",
        "    if args_modelType == 2:\n",
        "        up = torch.nn.Upsample(scale_factor=16, mode='bilinear')\n",
        "    else:\n",
        "        up = torch.nn.Upsample(size=(1096,1368), mode='bilinear')\n",
        "    if args_gpu:\n",
        "        up = up.cuda()\n",
        "\n",
        "    p = args_p\n",
        "    q = args_q\n",
        "    classes = args_classes\n",
        "    if args_modelType == 2:\n",
        "        modelA = Net.ESPNet_Encoder(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'encoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(\n",
        "            q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/encoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    elif args_modelType == 1:\n",
        "        modelA = Net.ESPNet(classes, p, q)  # Net.Mobile_SegNetDilatedIA_C_stage1(20)\n",
        "        model_weight_file = args_weightsDir + os.sep + 'decoder' + os.sep + 'espnet_p_' + str(p) + '_q_' + str(q) + '.pth'\n",
        "        if not os.path.isfile(model_weight_file):\n",
        "            print('Pre-trained model file does not exist. Please check ../pretrained/decoder folder')\n",
        "            exit(-1)\n",
        "        modelA.load_state_dict(torch.load(model_weight_file))\n",
        "    else:\n",
        "        print('Model not supported')\n",
        "    # modelA = torch.nn.DataParallel(modelA)\n",
        "    if args_gpu:\n",
        "        modelA = modelA.cuda()\n",
        "\n",
        "    # set to evaluation mode\n",
        "    modelA.eval()\n",
        "\n",
        "    if not os.path.isdir(args_savedir):\n",
        "        os.mkdir(args_savedir)\n",
        "\n",
        "    evaluateModel_resizeInput(modelA, up, image_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPnsG9XYc6kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "main_resizeInput()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bcBQyoSws9ms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### visualize results"
      ]
    },
    {
      "metadata": {
        "id": "aK4ZGVLys9ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls ./results1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j7NBn2mks9mu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(\"./results1/over_frame00000.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Js4v7hPBs9mx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lj1uHw1Js9my",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 20 -pattern_type glob -i 'results1/over_*.jpg' -c:v libx264 -pix_fmt yuv420p over_bag1.mp4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gibTKTfws9m2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('over_bag1.mp4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxVVdpuwYQ00",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o5mFdCRzNI74",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv over_bag1.mp4 /content/drive/apex/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S59eLb6eMS7c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# retrain model (binary, cityscapes)"
      ]
    },
    {
      "metadata": {
        "id": "VoEwOzm3lL7v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPBMwxj1lL71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp /content/ESPNet/train/city/* /content/datasets/cityscapes/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W_QYyqMwlL7-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### train on small set (20 train, 20 val)"
      ]
    },
    {
      "metadata": {
        "id": "_UC3mUr2lL7_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cd /content/datasets/cityscapes/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlZO5rKflL8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#rm -r train.txt val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yjki2TnolL8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#mv train_small.txt train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2wWPqiaNlL8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#mv val_small.txt val.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUTBYdB0vTuj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder"
      ]
    },
    {
      "metadata": {
        "id": "3HA3KmmMAZy4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "eBcX-jIlAor2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wouDPwy5APNY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --scaleIn 8 --data_dir /content/datasets/cityscapes/ --savedir /content/drive/espnet_checkpoints/encoder/ --classes 2 --batch_size 14 --max_epochs 300 --num_workers 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HavdqwjZAcY4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "wwNz5dyBAo7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sbw7X6m1N14s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --scaleIn 8 --data_dir /content/datasets/cityscapes/ --savedir /content/drive/espnet_checkpoints/encoder/ --classes 2 --batch_size 14 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/espnet_checkpoints/encoder/_enc_2_8/checkpoint.pth.tar "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9z8QIpDklL7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder"
      ]
    },
    {
      "metadata": {
        "id": "zTKMsRtflL8l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "mjXb_1FtlL8m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DPK-hlR_lL8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --scaleIn 1 --decoder True --pretrained /content/drive/espnet_checkpoints/encoder/epoch219_950_espnet_p_2_q_8.pth --data_dir /content/datasets/cityscapes/ --savedir /content/drive/espnet_checkpoints/decoder/ --classes 2 --batch_size 12 --max_epochs 300 --num_workers 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2E5hltElL80",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "xZYs4f5slL81",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nUDsZn64lL85",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main.py --scaleIn 1 --decoder True --pretrained /content/drive/espnet_checkpoints/encoder/epoch219_950_espnet_p_2_q_8.pth --data_dir /content/datasets/cityscapes/ --savedir /content/drive/espnet_checkpoints/decoder/ --classes 2 --batch_size 12 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/espnet_checkpoints/decoder/_dec_2_8/checkpoint.pth.tar "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "weO1D-z1P5jB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# retrain model (binary, apex)"
      ]
    },
    {
      "metadata": {
        "id": "4aDXzRL3P5jB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gOI9bkaupV9a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/datasets/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GoBTicwaonnR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/drive/apex/annotated/apex_annotated.zip -d /content/datasets/apex/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "teOcYKKFP5jE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def relabel():\n",
        "  i = 1\n",
        "  for imgpath in os.listdir(os.getcwd()):\n",
        "    labelOrig = Image.open(imgpath)\n",
        "    labelOrig = labelOrig.convert(mode = \"L\")\n",
        "    labelNumpy = np.array(labelOrig)\n",
        "    labelNumpy[labelNumpy==142] = 1\n",
        "    im2 = Image.fromarray(labelNumpy)\n",
        "    im2.save(imgpath)\n",
        "    if i%10 == 0:\n",
        "      print(i)\n",
        "    i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CAdrGLT33RAh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/apex/train/labels/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWYNASbl3nd6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "relabel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cWXvn5BI3zkz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/apex/val/labels/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uGaeSHLe3zk1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "relabel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KoFhRwm8P5jK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder"
      ]
    },
    {
      "metadata": {
        "id": "h2GB-zfZP5jK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "juZA2UaoP5jL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "luiUW8MnP5jL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 8 --data_dir /content/datasets/apex/ --savedir /content/drive/apex_espnet_checkpoints/encoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tYXBjODGP5jN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "ob_sBV4xP5jO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "axJKxCKdP5jO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 8 --data_dir /content/datasets/apex/ --savedir /content/drive/apex_espnet_checkpoints/encoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/apex_espnet_checkpoints/encoder/_enc_2_8/checkpoint.pth.tar --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H70FAaC5P5jP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder"
      ]
    },
    {
      "metadata": {
        "id": "poIEWoa6P5jP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "id": "sT7pgYr1P5jQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "riQoDjlkP5jR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 1 --decoder True --pretrained /content/drive/apex_espnet_checkpoints/encoder/_enc_2_8/model_261.pth --data_dir /content/datasets/apex/ --savedir /content/drive/apex_espnet_checkpoints/decoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PkVqevP_P5jS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "id": "qiV1kPSQP5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E3vaHQtlP5jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 1 --decoder True --pretrained /content/drive/apex_espnet_checkpoints/encoder/_enc_2_8/model_261.pth --data_dir /content/datasets/apex/ --savedir /content/drive/apex_espnet_checkpoints/decoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/apex_espnet_checkpoints/decoder/_dec_2_8/checkpoint.pth.tar --inWidth 1368 --inHeight 1096  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tKUbLQLPhqjl"
      },
      "cell_type": "markdown",
      "source": [
        "# retrain model (binary, apex_test)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "ZgrWhVhMhqjl"
      },
      "cell_type": "code",
      "source": [
        "!pip install graphviz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "tYKhNlzjhqjn"
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/datasets/apex"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "o24Jdfqihqjo"
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip /content/drive/apex/annotated/apex_annotated_test.zip -d /content/datasets/apex/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "G5LreDrQhqjq"
      },
      "cell_type": "code",
      "source": [
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def relabel():\n",
        "  i = 1\n",
        "  for imgpath in os.listdir(os.getcwd()):\n",
        "    labelOrig = Image.open(imgpath)\n",
        "    labelOrig = labelOrig.convert(mode = \"L\")\n",
        "    labelNumpy = np.array(labelOrig)\n",
        "    labelNumpy[labelNumpy==142] = 1\n",
        "    im2 = Image.fromarray(labelNumpy)\n",
        "    im2.save(imgpath)\n",
        "    if i%10 == 0:\n",
        "      print(i)\n",
        "    i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "_0YuM800hqjt"
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/apex/train/labels/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "brbLF1qLhqju"
      },
      "cell_type": "code",
      "source": [
        "relabel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "l4bzas2lhqjw"
      },
      "cell_type": "code",
      "source": [
        "cd /content/datasets/apex/val/labels/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "aoxpG9KFhqjx"
      },
      "cell_type": "code",
      "source": [
        "relabel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pWJ-IK04hqj0"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain encoder"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KKwg0jYlhqj1"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "iEHADYMrhqj1"
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "wzKo64bfhqj2",
        "outputId": "2224a27a-4808-4923-ef75-ec9dc1599e4d"
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 8 --data_dir /content/datasets/apex/ --savedir /content/drive/apex_test_espnet_checkpoints/encoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[57/62] loss: 0.046 time:1.29\n",
            "[58/62] loss: 0.026 time:1.30\n",
            "[59/62] loss: 0.020 time:1.28\n",
            "[60/62] loss: 0.036 time:1.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Yr6Lrdxdhqj4"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "0p-XNysfhqj4"
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "YSk0fGc8hqj6"
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 8 --data_dir /content/datasets/apex/ --savedir /content/drive/apex_test_espnet_checkpoints/encoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/apex_test_espnet_checkpoints/encoder/_enc_2_8/checkpoint.pth.tar --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6bS73xoJhqj7"
      },
      "cell_type": "markdown",
      "source": [
        "##retrain decoder"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jObKDqqKhqj7"
      },
      "cell_type": "markdown",
      "source": [
        "### start training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "8FQPavTyhqj8"
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "Ua59Zosqhqj-"
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 1 --decoder True --pretrained /content/drive/apex_test_espnet_checkpoints/encoder/_enc_2_8/model_261.pth --data_dir /content/datasets/apex/ --savedir /content/drive/apex_test_espnet_checkpoints/decoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --inWidth 1368 --inHeight 1096 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZxAjRspzhqkA"
      },
      "cell_type": "markdown",
      "source": [
        "###resume training"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "h2ywmPpOhqkB"
      },
      "cell_type": "code",
      "source": [
        "cd /content/ESPNet/train/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "colab": {},
        "id": "0voOet_ghqkD"
      },
      "cell_type": "code",
      "source": [
        "!python3 main_apex.py --scaleIn 1 --decoder True --pretrained /content/drive/apex_test_espnet_checkpoints/encoder/_enc_2_8/model_261.pth --data_dir /content/datasets/apex/ --savedir /content/drive/apex_test_espnet_checkpoints/decoder/ --classes 2 --batch_size 4 --max_epochs 300 --num_workers 4 --resume True --resumeLoc /content/drive/apex_test_espnet_checkpoints/decoder/_dec_2_8/checkpoint.pth.tar --inWidth 1368 --inHeight 1096  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}